{"name":"Practical-machine-learning","tagline":"Practical Machine Learning Course Project","body":"---\r\ntitle: \"Practical Machine Learning - Course Project\"\r\nauthor: \"Sai krishnan\"\r\ndate: \"Saturday, February 21, 2015\"\r\noutput:\r\n  html_document:\r\n    keep_md: yes\r\n---\r\n##Background  \r\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. In this project, data from accelerometers on the belt, forearm, arm, and dumbell of the 6 participants was collected. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Our goal is to build a model based on sensor data to predict whether the lift was performed correctly or not. \r\n\r\nData Sources  \r\n\r\nTraining dataset: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  \r\nTest dataset: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv  \r\n\r\nOutcome variable: \"classe\"  \r\n- lift exactly according to the specification (category 'A')  \r\n- throwing the elbows to the front            (category 'B')  \r\n- lifting the dumbbell only halfway           (category 'C')  \r\n- lowering the dumbbell only halfway          (category 'D')  \r\n- throwing the hips to the front              (category 'E')  \r\n\r\n## Data Cleaning & Exploratory Analysis  \r\n  \r\n```{r echo=TRUE}\r\n# Load the training and test datasets from working directory; replace missing values with 'NA'\r\nharTrain <- read.csv(\"C:/Users/Admin/Documents/Practical Machine Learning/Project/pml-training.csv\",header=TRUE,na.strings=c(\"NA\",\"\")) \r\nharTest <- read.csv(\"C:/Users/Admin/Documents/Practical Machine Learning/Project/pml-testing.csv\",header=TRUE,na.strings=c(\"NA\",\"\"))\r\n\r\n# Delete columns with missing values\r\nharTrain <- harTrain[,colSums(is.na(harTrain)) == 0]\r\nharTest  <-  harTest[,colSums(is.na(harTest))  == 0]\r\n\r\n# Since we want to predict the type of lift using only activity monitor data, \r\n# the other variables (in columns 1 though 7) are eliminated from the datasets  \r\nharTrain <- harTrain[,-c(1:7)]\r\nharTest  <- harTest [,-c(1:7)]\r\n\r\n# Compare the sizes of the training and testing datasets  \r\ndim(harTrain); dim(harTest)\r\n\r\n# Summarize the values in the outcome variable (classe) of the training dataset\r\nsummary(harTrain$classe)\r\n```\r\nWe see that instances of correct lift (classe = 'A') are most (at 5580) as compared to the occurrences of each of the incorrect lifts.  \r\n\r\n## Data Preparation  \r\nThe training dataset is fairly large with `r nrow(harTrain)` rows and `r ncol(harTrain)` columns. We partition the training dataset using random sampling without replacement into the following 2 datasets to allow cross validation:  \r\n- harTrng (80% of training data)    \r\n- harVal  (20% of training data)  \r\n\r\n```{r echo=TRUE}\r\nlibrary(caret)\r\nset.seed(12345) # For reproducibility\r\ninTrain <- createDataPartition(y=harTrain$classe, p=0.80, list=FALSE)\r\nharTrng <- harTrain[inTrain,]\r\nharVal  <- harTrain[-inTrain,]\r\n```  \r\nThe core training dataset contains `r nrow(harTrng)` rows and the validation dataset contains `r nrow(harVal)` rows.  Comparing the the values of the training an validation sets:- \r\n```{r echo=TRUE}\r\npar(mfrow=c(1,2))\r\nplot(harTrng$classe, col=\"blue\", xlab=\"classe levels in Training dataset\", ylab=\"Frequency\")\r\nplot(harVal$classe, col=\"blue\", xlab=\"classe levels in validation dataset\", ylab=\"Frequency\")\r\n```\r\nWe observe that the distribution of outcomes is similar in both the training and validation datasets.  \r\n\r\n##Model Development for predicting exercise correctness  \r\n```{r echo=TRUE}\r\n#Load required packages\r\nlibrary(MASS)\r\nlibrary(rpart)\r\nlibrary(rpart.plot)\r\nlibrary(rattle)\r\n```\r\nUsing Decision Trees algorithm  \r\n```{r echo=TRUE}\r\ndtModel      <- rpart(classe ~ ., data=harTrng, method=\"class\")\r\ndtPrediction <- predict(dtModel, harVal, type = \"class\")\r\nfancyRpartPlot(dtModel)\r\n#Plot confusion matrix\r\nconfusionMatrix(dtPrediction, harVal$classe)\r\n```\r\nWe observe that the accuracy of the decision trees algorithm is 73.26% with an out of sample error at 26.74%.  \r\n\r\nUsing Naive Bayes algorithm  \r\n```{r echo=TRUE}\r\nlibrary(e1071) #Package required to run Naive Bayes algorithm\r\nnbModel      <- naiveBayes(classe ~ ., data=harTrng)\r\nnbPrediction <- predict(nbModel, newdata=harVal)\r\n#Plot confusion matrix\r\nconfusionMatrix(nbPrediction, harVal$classe)\r\n```\r\nThe model accuracy drops further to nearly 50% using the Naive Bayes algorithm. The out of sample error is very high in this case at nearly 50%.  \r\n\r\nUsing Random Forest algorithm  \r\n```{r echo=TRUE}\r\nlibrary(randomForest)  #Package required to run random forest algorithm\r\nset.seed(12345)\r\nrfModel      <- randomForest(classe ~. , data=harTrng, method=\"class\")\r\nrfPrediction <- predict(rfModel, harVal, type = \"class\")\r\n#Plot confusion matrix\r\nconfusionMatrix(rfPrediction, harVal$classe)\r\n```\r\nWe observe that the Random Forest algorithm gives the highest prediction accuracy amongst the three models. The model accuracy is 99.34% and the out of sample error is estimated at 0.66% which is the lowest amongst the three models we have tried.  \r\n\r\n##Prediction  \r\n\r\nWe choose the random forest model for prediction as follows:-  \r\n```{r echo=TRUE}\r\nprediction <- predict(rfModel, harTest, type=\"class\")\r\n#Display the 20 predicted values of classe for the test dataset \r\nprediction\r\n#Function to create files for loading data\r\npml_write_files = function(x){\r\n  n = length(x)\r\n  for(i in 1:n){\r\n    filename = paste0(\"problem_id_\",i,\".txt\")\r\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\r\n  }\r\n}\r\n#Create 20 files with prediction for each test case\r\npml_write_files(prediction)\r\n```\r\n#References  \r\nURL: http://groupware.les.inf.puc-rio.br/har  \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}